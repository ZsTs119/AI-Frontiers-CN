模型论文地址：https://arxiv.org/abs/2503.05447

模型概述：文章标题：《Linear-MoE: Linear Sequence Modeling Meets Mixture-of-Experts》
中文文章标题：《Linear-MoE：线性序列建模遇见混合专家》
文章内容：提出了一种线性混合专家模型Linear-MoE，通过减少参数和计算复杂度，提高长序列建模效率。
