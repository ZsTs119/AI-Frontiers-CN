模型论文地址：https://arxiv.org/abs/2505.17332

模型概述：当前标题：《SweEval: Do LLMs Really Swear? A Safety Benchmark for Testing Limits for Enterprise Use》
中文文章标题：《SweEval：LLM真的会发誓吗？用于测试企业使用极限的安全基准》
文章内容：研究者提出SweEval，一个用于评估大型语言模型在处理不当内容时的安全性和鲁棒性基准，发现LLM在处理侮辱性言语时仍存在缺陷。
