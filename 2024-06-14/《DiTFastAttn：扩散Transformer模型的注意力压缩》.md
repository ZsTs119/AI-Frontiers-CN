模型论文地址：https://arxiv.org/abs/2406.08552

模型概述：当前标题：《DiTFastAttn: Attention Compression for Diffusion Transformer Models》
中文文章标题：《DiTFastAttn：扩散Transformer模型的注意力压缩》
文章内容：提出DiTFastAttn方法，通过压缩注意力机制，提高扩散Transformer模型的效率，减少计算和存储需求。
