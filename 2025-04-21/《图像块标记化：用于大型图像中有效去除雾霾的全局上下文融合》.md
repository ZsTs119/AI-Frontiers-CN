模型论文地址：https://arxiv.org/abs/2504.09621

模型概述：当前标题：《Tokenize Image Patches: Global Context Fusion for Effective Haze Removal in Large Images》
中文文章标题：《图像块标记化：用于大型图像中有效去除雾霾的全局上下文融合》
文章内容：提出一种图像块标记化方法，通过全局上下文融合，有效处理大型图像中的雾霾去除问题。
