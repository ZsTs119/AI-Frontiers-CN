模型论文地址：https://arxiv.org/abs/2501.06425

模型概述：标题：《Tensor Product Attention Is All You Need》
中文文章标题：《张量积注意力机制是你所需要的全部》
文章内容：提出张量积注意力机制，改进Transformer架构，提升计算效率，减少参数数量。
