模型论文地址：https://arxiv.org/abs/2506.18674

模型概述：文章标题《Is There a Case for Conversation Optimized Tokenizers in Large Language Models?》，
中文文章标题《大型语言模型中是否有对话优化分词器的案例？》，
文章内容：探讨在大型语言模型中对话优化分词器的作用，提出对话优化分词器能提高语言模型的对话生成能力。
