模型论文地址：https://arxiv.org/abs/2407.09121

模型概述：文章标题：《Refuse Whenever You Feel Unsafe: Improving Safety in LLMs via Decoupled Refusal Training》
中文文章标题：《感觉不安全时拒绝：通过解耦拒绝训练提高LLM的安全性》
文章内容：提出一种解耦拒绝训练方法，增强大型语言模型的安全性，使其在感知潜在风险时能够自主拒绝生成不安全内容。
