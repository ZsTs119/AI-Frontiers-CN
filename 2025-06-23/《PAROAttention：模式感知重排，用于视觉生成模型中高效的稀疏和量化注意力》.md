模型论文地址：https://arxiv.org/abs/2506.16054

模型概述：文章标题：《PAROAttention: Pattern-Aware ReOrdering for Efficient Sparse and Quantized Attention in Visual Generation Models》
中文文章标题：《PAROAttention：模式感知重排，用于视觉生成模型中高效的稀疏和量化注意力》
文章内容：提出PAROAttention方法，通过模式感知重排优化视觉生成模型中的稀疏和量化注意力，提高计算效率。
