模型论文地址：https://arxiv.org/abs/2505.10475

模型概述：文章标题：《Parallel Scaling Law for Language Models》
中文文章标题：《语言模型的并行缩放法则》
文章内容：研究提出语言模型并行缩放法则，发现模型大小与训练资源间存在幂律关系，可预测模型性能提升。
