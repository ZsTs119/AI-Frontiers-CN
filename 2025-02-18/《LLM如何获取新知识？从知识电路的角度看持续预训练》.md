模型论文地址：https://arxiv.org/abs/2502.11196

模型概述：文章标题：《How Do LLMs Acquire New Knowledge? A Knowledge Circuits Perspective on Continual Pre-Training》
中文文章标题：《LLM如何获取新知识？从知识电路的角度看持续预训练》
文章内容：本文探讨了大型语言模型在持续预训练中如何获取新知识，提出知识电路视角，认为模型通过不断更新知识电路来学习新概念和模式。
