模型论文地址：https://arxiv.org/abs/2405.16287

模型概述：文章标题《'LoGAH: Predicting 774-Million-Parameter Transformers using Graph HyperNetworks with 1/100 Parameters'》，
中文文章标题《'LoGAH：使用1/100参数的图超网络预测774百万参数Transformer'》，
文章内容：提出LoGAH方法，使用图超网络以仅1/100的参数预测大规模Transformer模型。
