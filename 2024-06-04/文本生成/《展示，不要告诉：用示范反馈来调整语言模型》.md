# [未提及] - 《Show, Don't Tell: Aligning Language Models with Demonstrated Feedback》

**模型功能**：
论文探讨了通过示范反馈而非直接指导来训练语言模型，以此提高语言模型的性能和适应性，本质上是对文本生成相关能力的优化，使得模型能在训练后更好地生成符合要求的文本。

**arXiv 文章链接**：
[https://arxiv.org/abs/2406.00888](https://arxiv.org/abs/2406.00888)

**作者/团队**：
Yifan Mai、Liam Dugan、Yichen Jiang、Yao Fu、Siddhartha Brahma、Dipendra Misra、Mohammad Shoeybi、Mike Lewis、Yoshua Bengio、Samy Bengio

**发表日期**：
2024年6月3日

**研究进展**：
传统方法通常依赖直接的人类反馈（如奖励模型）来微调语言模型，但这些方法存在一些问题，如奖励模型难以准确反映真实的人类偏好等。该论文提出使用示范反馈的方法来训练语言模型，通过让模型观察示范示例来学习，而不是直接告知模型应该如何做。这种方法可以减少对奖励模型的依赖，提高模型在各种任务中的性能和适应性，是文本生成领域在训练方式上的一种创新探索。

**应用场景**：
可应用于自动写作、自动翻译、聊天机器人、文章续写、新闻撰写、剧本生成等需要文本生成的场景，经过优化训练后的模型能在这些场景中生成更优质、更符合用户需求的文本内容。