# Learning Temporally Consistent Video Depth from Video Diffusion Priors - 《Learning Temporally Consistent Video Depth from Video Diffusion Priors》

**模型功能**：该模型基于视频扩散先验的方法，通过学习时间一致的深度信息，以提高视频深度估计的准确性。

**arXiv 文章链接**：
[https://arxiv.org/abs/2406.01493](https://arxiv.org/abs/2406.01493)

**作者/团队**：Jianfei Cai、Jiawei Zhang、Ying-Cong Chen、Luc Van Gool

**发表日期**：2024年6月3日

**研究进展**：该研究创新性地利用视频扩散先验来学习时间一致的深度信息，这有助于解决视频深度估计中深度信息不一致的问题，提升了视频深度估计的准确性。目前在视频深度估计领域，考虑时间一致性是一个重要的研究方向，此模型为该方向提供了新的方法和思路。

**应用场景**：在视频合成、视频剪辑、动态内容生成等视频生成相关场景中，准确的视频深度信息可以用于增强视频的立体感和真实感；在自动驾驶中的视频生成场景，深度信息有助于模拟更真实的驾驶环境；在游戏中的视频生成场景，可用于打造更逼真的游戏画面。