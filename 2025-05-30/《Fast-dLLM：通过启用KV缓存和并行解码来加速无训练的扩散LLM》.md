模型论文地址：https://arxiv.org/abs/2505.22618

模型概述：文章标题：《Fast-dLLM: Training-free Acceleration of Diffusion LLM by Enabling KV Cache and Parallel Decoding》
中文文章标题：《Fast-dLLM：通过启用KV缓存和并行解码来加速无训练的扩散LLM》
文章内容：提出Fast-dLLM方法，通过启用KV缓存和并行解码，实现无训练需求的扩散LLM加速，提升生成效率与性能。
