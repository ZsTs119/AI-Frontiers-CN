模型论文地址：https://arxiv.org/abs/2504.16083

模型概述：标题：《MMInference: Accelerating Pre-filling for Long-Context VLMs via Modality-Aware Permutation Sparse Attention》
中文文章标题：《MMInference：通过模态感知排列稀疏注意力加速长上下文VLM的预填充》
文章内容：提出MMInference方法，通过模态感知排列稀疏注意力优化长上下文视觉语言模型预填充，提高推理效率。
