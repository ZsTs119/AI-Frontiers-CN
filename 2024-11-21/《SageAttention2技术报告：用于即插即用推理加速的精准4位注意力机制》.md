模型论文地址：https://arxiv.org/abs/2411.10958

模型概述：当前标题：《SageAttention2 Technical Report: Accurate 4 Bit Attention for Plug-and-play Inference Acceleration》
中文文章标题：《SageAttention2技术报告：用于即插即用推理加速的精准4位注意力机制》
文章内容：提出SageAttention2，一种4位精度的注意力机制，可提升推理速度，适用于即插即用加速。
