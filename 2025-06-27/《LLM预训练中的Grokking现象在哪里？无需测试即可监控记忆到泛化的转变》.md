模型论文地址：https://arxiv.org/abs/2506.21551

模型概述：当前标题：《Where to find Grokking in LLM Pretraining? Monitor Memorization-to-Generalization without Test》
中文文章标题：《LLM预训练中的Grokking现象在哪里？无需测试即可监控记忆到泛化的转变》
文章内容：研究提出一种新方法，通过监控训练过程中的权重变化，无需测试即可识别模型从记忆到泛化的转变，有助于理解LLM预训练中的Grokking现象。
