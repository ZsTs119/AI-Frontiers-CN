模型论文地址：https://arxiv.org/abs/2506.21103

模型概述：当前标题：《Learning to Skip the Middle Layers of Transformers》
中文文章标题：《学习跳过Transformer的中间层》
文章内容：提出一种新型Transformer架构，通过学习跳过部分中间层以减少计算负担，同时保持模型性能。
