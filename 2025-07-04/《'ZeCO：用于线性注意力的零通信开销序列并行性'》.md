模型论文地址：https://arxiv.org/abs/2507.01004

模型概述：文章标题《'ZeCO: Zero Communication Overhead Sequence Parallelism for Linear Attention'》
中文文章标题《'ZeCO：用于线性注意力的零通信开销序列并行性'》
文章内容：ZeCO是一种用于线性注意力机制的序列并行方法，通过消除通信开销提高了并行效率。
