# PLaD - PLaD: Preference-based Large Language Model Distillation with Pseudo-Preference Pairs

**模型功能**：
该模型提出PLaD方法，利用伪偏好对进行大语言模型蒸馏，以此提高偏好型模型的效率和性能。

**arXiv 文章链接**：
[https://arxiv.org/abs/2406.02886](https://arxiv.org/abs/2406.02886)

**作者/团队**：
Jianyi Wang、Tianyi Tang、Jiawei Han等。

**发表日期**：
2024年6月5日

**研究进展**：
当前大语言模型在偏好学习方面需要大量的人工标注偏好数据，成本高昂。PLaD方法创新性地使用伪偏好对来进行模型蒸馏，减少了对人工标注的依赖。在蒸馏过程中，它通过优化教师模型和学生模型之间的偏好一致性，有效地将教师模型的偏好知识转移到学生模型中，从而提高了偏好型模型的效率和性能。实验表明，PLaD在多个自然语言处理任务上取得了较好的效果。

**应用场景**：
自动写作、文章续写、新闻撰写等文本生成相关场景。在这些场景中，偏好型模型可以根据用户的偏好生成更符合需求的文本内容，而PLaD方法提高了偏好型模型的性能，能更好地满足用户的个性化文本生成需求。