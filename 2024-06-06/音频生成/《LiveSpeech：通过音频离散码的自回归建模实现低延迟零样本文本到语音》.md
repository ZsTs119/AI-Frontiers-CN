# LiveSpeech - LiveSpeech: Low-Latency Zero-shot Text-to-Speech via Autoregressive Modeling of Audio Discrete Codes

**模型功能**：
该模型利用自回归建模实现低延迟零样本文本到语音转换，能够提高生成速度和语音质量。

**arXiv 文章链接**：
[https://arxiv.org/abs/2406.02897](https://arxiv.org/abs/2406.02897)

**作者/团队**：
论文作者包括Chen Zhang、Jianyuan Zhong、Yangjun Ruan等。

**发表日期**：
2024年6月5日

**研究进展**：
LiveSpeech提出了一种基于音频离散码自回归建模的新方法，实现了低延迟的零样本文本到语音转换。它通过在多个音频数据集上进行训练，学习到通用的语音特征，从而能够在零样本的情况下将文本转换为语音。与传统方法相比，LiveSpeech显著提高了生成速度，同时保持了较高的语音质量。该模型在低延迟和零样本学习方面具有创新性，为实时语音合成提供了更有效的解决方案。

**应用场景**：
智能语音助手、语音提示、语音转文本、语音克隆、虚拟主播等语音合成相关场景。