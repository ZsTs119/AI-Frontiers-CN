模型论文地址：https://arxiv.org/abs/2507.07996

模型概述：文章标题：《Skip a Layer or Loop it? Test-Time Depth Adaptation of Pretrained LLMs》
中文文章标题：《跳过一层还是循环它？预训练LLM的测试时深度适应》
文章内容：探讨了在测试时调整预训练语言模型深度的策略，提出了一种根据任务需求动态调整模型深度的方法。
