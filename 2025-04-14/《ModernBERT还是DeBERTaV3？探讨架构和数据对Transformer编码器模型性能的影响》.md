模型论文地址：https://arxiv.org/abs/2504.08716

模型概述：文章标题：《ModernBERT or DeBERTaV3? Examining Architecture and Data Influence on Transformer Encoder Models Performance》，
中文文章标题：《ModernBERT还是DeBERTaV3？探讨架构和数据对Transformer编码器模型性能的影响》，
文章内容：本文对比了ModernBERT和DeBERTaV3，分析不同架构和数据对Transformer编码器模型性能的影响。
