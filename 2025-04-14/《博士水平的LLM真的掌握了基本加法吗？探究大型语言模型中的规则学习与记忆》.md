模型论文地址：https://arxiv.org/abs/2504.05262

模型概述：当前标题：《Do PhD-level LLMs Truly Grasp Elementary Addition? Probing Rule Learning vs. Memorization in Large Language Models》
中文文章标题：《博士水平的LLM真的掌握了基本加法吗？探究大型语言模型中的规则学习与记忆》
文章内容：研究探究大型语言模型在学习基本加法时，是依赖规则学习还是记忆，发现LLM在处理简单数学问题时有局限性。
