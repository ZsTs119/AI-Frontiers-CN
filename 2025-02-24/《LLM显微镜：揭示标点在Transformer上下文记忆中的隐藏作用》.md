模型论文地址：https://arxiv.org/abs/2502.15007

模型概述：文章标题：《LLM-Microscope: Uncovering the Hidden Role of Punctuation in Context Memory of Transformers》
中文文章标题：《LLM显微镜：揭示标点在Transformer上下文记忆中的隐藏作用》
文章内容：研究者通过LLM-Microscope工具发现，标点符号在Transformer模型处理上下文信息时具有重要作用，影响其记忆能力。
