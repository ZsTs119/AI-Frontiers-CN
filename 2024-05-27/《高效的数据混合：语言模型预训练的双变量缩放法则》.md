模型论文地址：https://arxiv.org/abs/2405.14908

模型概述：当前标题：《Data Mixing Made Efficient: A Bivariate Scaling Law for Language Model Pretraining》
中文文章标题：《高效的数据混合：语言模型预训练的双变量缩放法则》
文章内容：研究提出了一种新的语言模型预训练方法，通过双变量缩放法则实现数据混合的高效性，显著提高了预训练模型的性能。
