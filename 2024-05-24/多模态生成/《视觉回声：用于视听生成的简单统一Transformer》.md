# Visual Echoes - Visual Echoes: A Simple Unified Transformer for Audio-Visual Generation

**模型功能**：
该模型是一种新的简单统一Transformer模型，通过联合学习音频和视觉信息，实现高效的视听生成。

**arXiv 文章链接**：
[https://arxiv.org/abs/2405.14598](https://arxiv.org/abs/2405.14598)

**作者/团队**：
文章作者为Xingyu Chen, Yilun Du, Antonio Torralba, Sanja Fidler。

**发表日期**：
2024年5月25日。

**研究进展**：
文章提出了一种简单而高效的方法来学习音频和视觉模态之间的联合表示，通过将视觉和音频输入转换为一系列离散的标记，并使用单个Transformer模型来生成这些标记，实现了多模态生成。该模型在多个视听数据集上进行了评估，证明了其在视听生成任务中的有效性和通用性。与现有方法相比，该模型具有简单统一的架构，避免了复杂的多模态融合策略，且能够在零样本和少样本设置下进行有效的视听生成。

**应用场景**：
典型应用场景包括跨模态检索、跨模态生成、多模态推荐系统等。例如，可以根据视觉信息生成对应的音频，或者根据音频信息生成相关的视觉内容，还可以用于智能客服、多模态搜索等领域，实现更自然和丰富的人机交互。