模型论文地址：https://arxiv.org/abs/2504.06261

模型概述：标题：《Hogwild! Inference: Parallel LLM Generation via Concurrent Attention》
中文文章标题：《Hogwild！推理：通过并发注意力实现并行LLM生成》
文章内容：提出Hogwild!推理方法，利用并发注意力机制在多GPU上高效生成大型语言模型，提升并行生成速度和效率。
