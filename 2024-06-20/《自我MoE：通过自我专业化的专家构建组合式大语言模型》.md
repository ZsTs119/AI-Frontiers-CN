模型论文地址：https://arxiv.org/abs/2406.12034

模型概述：文章标题：《Self-MoE: Towards Compositional Large Language Models with Self-Specialized Experts》
中文文章标题：《自我MoE：通过自我专业化的专家构建组合式大语言模型》
文章内容：提出自我MoE模型，通过自学习专家模块实现大语言模型的组合式结构，提升模型性能和泛化能力。
