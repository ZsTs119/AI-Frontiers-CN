# DevEval - DevEval: A Manually-Annotated Code Generation Benchmark Aligned with Real-World Code Repositories

**模型功能**：
该模型提出了DevEval基准，这是一个针对代码生成的手动注释数据集，通过与实际代码仓库对齐，旨在提升生成代码的质量。

**arXiv 文章链接**：
[https://arxiv.org/abs/2405.19856](https://arxiv.org/abs/2405.19856)

**作者/团队**：
论文作者为Shangqing Liu, Chenglin Miao, Xinyu Wang, Qingwei Lin, Daxin Jiang, and Michael R. Lyu。

**发表日期**：
2024年5月31日。

**研究进展**：
目前代码生成模型在评估方面存在不足，而DevEval基准填补了这一空白。它手动标注的特性使其能更好地反映真实代码仓库的情况，相较于其他评估方法更具真实性和可靠性，能为代码生成模型提供更有效的评估，促进代码生成技术的发展。

**应用场景**：
主要应用于软件开发领域，可用于代码生成模型的评估和训练，帮助开发者提升代码生成的质量，还可用于数据增强，为模型训练提供更优质的数据集。