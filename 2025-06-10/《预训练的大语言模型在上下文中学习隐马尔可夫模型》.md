模型论文地址：https://arxiv.org/abs/2506.07298

模型概述：当前标题：《Pre-trained Large Language Models Learn Hidden Markov Models In-context》
中文文章标题：《预训练的大语言模型在上下文中学习隐马尔可夫模型》
文章内容：研究表明，预训练的大语言模型能够在上下文中学习并模拟隐马尔可夫模型。
