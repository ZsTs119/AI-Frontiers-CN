# SpeechGuard - SpeechGuard: Exploring the Adversarial Robustness of Multimodal Large Language Models

**模型功能**：该模型提出了SpeechGuard框架，能够增强多模态大型语言模型对对抗性攻击的鲁棒性，提高模型在真实环境中的表现和安全性。

**arXiv 文章链接**：
[https://arxiv.org/abs/2405.08317](https://arxiv.org/abs/2405.08317)

**作者/团队**：论文作者包括Zihan Wang、Tianwei Zhang等。

**发表日期**：2024年5月14日

**研究进展**：此研究聚焦于多模态大型语言模型在对抗性攻击下的鲁棒性问题。以往多模态模型在面对对抗攻击时可能存在表现下降和安全隐患，而SpeechGuard框架通过特定方法增强了模型对这类攻击的抵御能力，是在多模态模型安全和鲁棒性方面的创新探索。

**应用场景**：可应用于需要多模态处理且对安全性和鲁棒性要求较高的场景，如智能客服、多模态搜索、跨模态检索等，确保模型在复杂环境下能稳定、安全地运行。