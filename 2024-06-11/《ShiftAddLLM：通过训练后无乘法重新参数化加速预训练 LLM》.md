模型论文地址：https://arxiv.org/abs/2406.05981

模型概述：标题：《ShiftAddLLM: Accelerating Pretrained LLMs via Post-Training Multiplication-Less Reparameterization》
中文文章标题：《ShiftAddLLM：通过训练后无乘法重新参数化加速预训练 LLM》
文章内容：提出ShiftAddLLM方法，通过训练后无乘法重新参数化，减少浮点运算，提升预训练语言模型效率。
